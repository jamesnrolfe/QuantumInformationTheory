---
dg-publish: true
---
#Notes 

We will only need to consider one specific type to demonstrate [[9.2 Non-locality of quantum theory#^f08d7d|Bell's theorem]]. As such, we don't need a full theory of hidden variables, only one simpler model which is able to explain just this type of experiment. This is a lot easier - we refer to this special sub-case as a **local hidden variable model**.

Consider a situation where Alice and Bob, separated in space, perform a set of experiments, where in each one they locally perform measurements on half of an entangled state. We will abstractly label the measurement made by Alice as $x$ and the measurement made by Bob as $y$. We always denote the outcomes of $x$ as $a$ and the outcomes of $y$ as $b$.

![[Screenshot 2025-03-02 at 18.16.12.png]]

We need to use a more abstract way of writing this because we don't want to refer explicitly to quantum formalism, but only to general, theory independent aspects.


> [!example] Example
> Consider that Alice and Bob share the *maximally entangled state*
> $$|\Phi \rangle=\frac{|00\rangle +|11\rangle }{\sqrt{ 2 }}$$
> Let Alice perform in one experiment a measurement of $X$, and in another a measurement of $Z$. We will label the first measurement by $x=0$ and the second $x=1$. In either case, we call the outcome $a$, which could either be $+1$ or $-1$. 
> We do a similar thing for Bob.
> In total, we will therefore consider 4 different experiments - one where they both measure $X$, one where they both measure $Z$ and two where they measure different operators.
> In each experiment, there are four possible *pairs* of outcomes based on the results they obtain: they both get $+1$, they both get $-1$, and two cases where one gets $+1$ and the other gets $-1$.

We can collect all the statistics produced by such collections of experiments into a set of conditional probabilities:

$$
P(a,b|x,y)
$$

There are thus 16 probabilities we are interested (four for each operator combination, of which there are 4 combinations). 

Considering the example above, the probabilities that will be observed can be calculated using the standard rules for performing measurements on quantum states. For example

$$
\begin{align}
 & P(+1,+1|0,0)=P(-1,-1|0,0)=\frac{1}{2};\quad P(+1,-1|0,0)=P(-1,+1|0,0)=0 \\
 & P(+1,+1|0,1)=P(-1,-1|0,1)=P(+1,-1|0,1)=P(-1,+1|0,1)=\frac{1}{4} \\
 & P(+1,+1|1,0)=P(-1,-1|1,0)=P(+1,-1|1,0)=P(-1,+1|1,0)=\frac{1}{4} \\
 & P(+1,+1|1,1)=P(-1,-1|1,1)=\frac{1}{2};\quad P(+1,-1|1,1)=P(-1,+1|1,1)=0
\end{align}

$$

i.e. for the first two probabilities, the probability that both get +1 given that they both measure $X$ is equal to the probability that they both get $-1$ given that they both measure $X$, which is equal to $\frac{1}{2}$.

> [!help] Note
> To see the above, it is obvious when you realised that the "given that" term essentially means you can treat it as if they both *definitely* used $X$. Remember, $X$ is diagonalised with eigenvectors $|+\rangle$ and $|-\rangle$, so we must write $|\Phi \rangle$ in terms of these eigenvectors to find the outcomes properly. It follows from that then that
> $$P(+1,-1|0,0)=P(-1,+1|0,0)=0$$

The probabilities $P(a,b|x,y)$ would be called *local* if they can also be reproduced by a local hidden variable model. 

Such a model would say that instead of making measurements on quantum systems in order to generate outcomes $a$ and $b$, in fact there were random variables sent to Alice and Bob, one corresponding to each measurement. Instead of performing measurements on quantum particles, the model says that there is *one random variable associated with each measurement* and *the value that random variable takes is the result of the measurement*. 

![[Screenshot 2025-03-02 at 18.29.28.png]]
*A probabilistic source $S$ emits hidden variables $\lambda$ to Alice and $\mu$ to Bob with probability distribution $P_{S}(\lambda,\mu)$. $\lambda=(a_{0},a_{1},\dots)$ specifies a deterministic list of outcomes such that $a=a_{x}$ when Alice thinks she performs a measurement labelled $x$, and similar case for Bob.*

In each run of the experiment, Alice might get a different list $\lambda=(a_{0},a_{1},\dots)$ and Bob a different list $\mu=(b_{0},b_{1},\dots)$, according to the joint probability distribution $P_{S}(\lambda,\mu)$. We say that a pair of lists $\lambda$ and $\mu$ correspond to a **deterministic strategy** as they are completely decided beforehand. *Crucially*, because they are determined by a *joint* probability distribution, there can be *correlations* - but these have a local explanation since they were created in the past from the same source. 

In this specific example that we are using where Alice receives $x$ and Bob receives $y$, the (conditional) probabilities that will be generated by such a local hidden variable model will just be the *average* over the source.

$$
P(a,b|x,y)=\sum_{\lambda,\mu} P_{S}(\lambda,\mu)P_{A}(a|x,\lambda)P_{B}(b|y,\mu)=\sum_{\lambda,\mu }P_{S}(\lambda,\mu)\delta_{a,a_{x}}\delta_{b,b_{y}}
$$


> [!help] Note
> We can use Kronecker deltas here because in a deterministic hidden variable model, $P_{A}(a|x,\lambda)$ represents a fixed, predetermined outcome rather than a probability distribution. What it is actually saying is what is the probability that we obtain a measurement outcome $a$ given that we measure (or "think" that we measure) with $x$ and the hidden random variable given to use by the source is $\lambda$.
> As $\lambda$ already encodes all possible measurement outcomes, the probability that Alice observes $a$ when measuring $x$ is 1 if $a=a_{x}$ (where $a_{x}$ is the predetermined measurement outcome from $\lambda$), and 0 otherwise. 
> So essentially
> $$P_{A}(a|x,\lambda)=\begin{cases} 1 & \text{if } a=a_{x} \\0  & \text{if } a\neq a_{x}\end{cases}$$

That is, the source $S$ sends the "results" of the supposes measurements $\lambda$ to Alice and $\mu$ to Bob with probability $P(\lambda,\mu)$. In Alice's lab, instead of making a measurement $x$, the model gives her the result to her "measurement" as with outcome $a=a_{x}$, from the list $\lambda$, and similarly for Bob.

This is why we call it *hidden* - we only observe the outcomes $a$ and $b$, and none of the internal workings. 

We take the above equation 

$$
P(a,b|x,y)=\sum_{\lambda,\mu} P_{S}(\lambda,\mu)P_{A}(a|x,\lambda)P_{B}(b|y,\mu)=\sum_{\lambda,\mu }P_{S}(\lambda,\mu)\delta_{a,a_{x}}\delta_{b,b_{y}}
$$

to define *what it means for the probabilities $P(a,b|x,y)$ be local*. Whenever it is possible to reproduce the statistics generated by a given experiment with a local model, then there is nothing non-local about the probabilities $P(a,b|x,y)$. 

> [!example] Example
>As an example, the probabilities considered above when Alice and Bob each measured with either $X$ or $Z$ are in fact local i.e. they can be reproduced using this model.
>
>![[Screenshot 2025-03-03 at 13.28.34.png]]
>
>In the above table, we specify deterministic strategies $(\lambda,\mu)$ with corresponding probabilities $P_{S}(\lambda,\mu)$ (these are the rows of the table). 
>In the case that Alice and Bob make use of the first strategy, it says that no matter what measurement each of them think they are making, they will *always* find $+1$. In this way, all of their results are perfectly correlated with each other. 
>However, in the other rows, the correlations are not perfect, and this affects the *average* correlations they observe when using this model. 

First, let us look in a little detail at this model (see above example) to check that it works properly. Each row corresponds to a different strategy, and in this case, there are 4 possible strategies each with equal probability. This means the observed behaviour $P(a,b|x,y)$ are in fact an average of four distinct (deterministic) behaviors. 

In the first strategy, the result of Alice's measurement of $X$ ($a_{0}$) is $+1$, and the result of measurement $Z$ ($a_{1}$) is also $+1$. This is the same for Bob. If Alice and Bob were to use *only* this strategy, then the associated probabilities that they would observe are

$$P(+1,+1|0,0)=P(+1,+1|0,1)=P(+1,+1|1,0)=P(+1,+1|1,1)=1$$

>[!help] Note
>Remember that we are looking at $P(a,b|x,y)$, so the first $+1$'s are the measurement outcomes for Alice and Bob, and the $x,y$'s are the measurement operators that they are using $X:x,y=0$, $Z:x,y=1$.

This is not the same as what we found above

$$
P(+1,+1|0,0)=P(+1,+1|1,1)=0;\quad P(+1,+1|0,1)=P(+1,+1|1,0)=\frac{1}{4}
$$

and so only using the first strategy all the time would not produce the results we want.

For the other three rows, considering them individually (like we just did), we find

$$
\begin{align}
\text{row 2:}\quad &  P(+1,+1|0,0)=P(+1,-1|0,1)=P(-1,+1|1,0)=P(-1,-1|1,1)=1 \\

\text{row 3:}\quad &  P(-1,-1|0,0)=P(-1,+1|0,1)=P(+1,-1|1,0)=P(+1,+1|1,1)=1 \\

\text{row 4:}\quad &  P(-1,-1|0,0)=P(-1,-1|0,1)=P(-1,-1|1,0)=P(-1,-1|1,1)=1
\end{align}

$$

In all the above cases, the probabilities that are not in the above vanish entirely, and so we clearly don't produce the measurements that we desired before.

But, what if we do all strategies, each with a $\frac{1}{4}$ chance of occurring? Well, to do this then in this case, we just sum up all the strategies and divide by 4 (thanks to uniform distribution of strategies). If we did this calculation, we would arrive at what we desired earlier. So, the model *can* reproduce these probabilities.

How did we arrive at this model? There are two steps that we can take to get there. The first step is to rule out certain strategies. We can do this by looking at the probabilities that are zero in $P(a,b|x,y)$. In our example above, there are four probabilities that are zero.

$$
P(+1,-1|0,0) = P(-1,+1|0,0)=P(+1,-1|1,1)=P(-1,+1|1,1)=0
$$

Focus initially on $P(+1,-1|0,0)=0$. Imagine there was a strategy where $a_{0}=+1$ and $b_{0}=-1$. If we were to use such a strategy with certainty, it would predict $P(+1,-1|0,0)=1$ which is not what we want to produce. If we were to use it not certainly but with some non-zero probability $P_{S}$, we would still have $P(+1,-1|0,0)>0$ which is inconsistent with what we want to produce. This shows that we can never use this strategy where $a_{0}=+1$ and $b_{0}=-1$, and all strategies where this is the case can be discounted i.e. $\lambda=(a_{0},+1)$, 
