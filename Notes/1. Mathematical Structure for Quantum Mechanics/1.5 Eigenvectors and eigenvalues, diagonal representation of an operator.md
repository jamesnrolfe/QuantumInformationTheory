---
noteID: ea252aeb-1ef4-4718-8d8f-a06ba57daeff
---
An **eigenvector** of an operator $A$ is a vector $|v\rangle$ satisfying

$$ A|v\rangle=\lambda |v\rangle $$

for some complex $\lambda$ - the **eigenvalue**. The eigenvalues and eigenvectors can be found by looking at the matrix of $A$ with respect to some orthonormal basis, and finding the eigenvalues and eigenvectors in the normal way (see the example below).

A **diagonal representation** of an operator $A$ on $\mathbb{C} ^n$ is

$$ A=\sum_{i=0}^{n-1} \lambda_i |v_i\rangle\langle v_i| $$

where $\lambda_i$ is the $i$-th eigenvalue of $A$ and the vectors $|v_i\rangle$ form an orthonormal basis. The diagonal representation is useful because it allows us to simplify calculations and visualise the action of the operator.

Note that all the vectors $|v_i\rangle$ in the diagonal representation of $A$ are eigenvectors of $A$. To see this, consider the action of $A$ on some vector $|v_k\rangle$ in this basis.

$$ A|v_k\rangle =\bigg (\sum_{i=0}^{n-1} \lambda_i |v_i\rangle\langle v_i| \bigg )|v_k\rangle=\sum_{i=0}^{n-1} \lambda_i |v_i\rangle\langle v_i|v_k\rangle=\lambda_k|v_k\rangle $$

since $\langle v_i|v_k\rangle \neq 0$ _only_ for $i=k$, where it equals one.

> [!Example]
> Consider some operator $X$ with a matrix
> 
> $$ \sigma_x=\begin{pmatrix} 0 & 1 \\ 1 & 0\end{pmatrix} $$
> 
> with respect to the standard basis. The usual equation for eigenvalues is $\det(\sigma_x-\lambda I)=0$, and in this case, it yields $\lambda =\pm 1$. We could then quite simply work out the eigenvectors using the original matrix eigenvalue equation $\sigma_x \vec v =\lambda \vec v$ or $X|v\rangle=\lambda |v\rangle$.
> 
> $$ \begin{aligned}\lambda =1: \quad & \vec v_1=\frac{1}{\sqrt 2}\begin{pmatrix}1\\1\end{pmatrix} \quad |v_1\rangle=\frac{1}{\sqrt2}\big (|0\rangle+|1\rangle \big ) \\\lambda =-1: \quad & \vec v_{-1}=\frac{1}{\sqrt 2}\begin{pmatrix}1\\-1\end{pmatrix} \quad |v_{-1}\rangle=\frac{1}{\sqrt2}\big (|0\rangle-|1\rangle \big ) \end{aligned} $$
> 
> We could work out the $X|v_1\rangle=|v_1\rangle$, and that $X|v_{-1}\rangle=-|v_{-1}\rangle$, as we would expect.
> 
> The diagonal representation of $X$ can now be found.
> 
> $$ \begin{aligned}X&=\sum_i \lambda_i |v_i\rangle\langle v_i| \\&= 1 \times |v_1\rangle\langle v_1|-1\times |v_{-1}\rangle\langle v_{-1}| \\ &= \bigg( \frac{|0\rangle+|1\rangle}{\sqrt2}\bigg)\bigg( \frac{\langle0|+\langle1|}{\sqrt2}\bigg)-\bigg( \frac{|0\rangle-|1\rangle}{\sqrt2}\bigg)\bigg( \frac{\langle0|-\langle1|}{\sqrt2}\bigg) \\ &=|0\rangle\langle 1|+|1\rangle\langle0|\end{aligned} $$
> 
> which is the expression for $X$ we saw in [1.4: Dirac notation for operators](https://www.notion.so/1-4-Dirac-notation-for-operators-162420b0cf9f80278fa9c6f6230cb76c?pvs=21).
> 


If an operator has the property that more than orthogonal eigenstate correspond to the same eigenvalue, then the eigenvalue is said to be _degenerate_. Consider the following operator on $\mathbb{C} ^3$.

$$ |0\rangle\langle 0 |+|1\rangle\langle1|-|2\rangle\langle 2| $$

where $\{|0\rangle,|1\rangle,|2\rangle\}$ is the standard orthonormal basis for $\mathbb{C} ^3$.

We can see clearly that the states $|0\rangle$ and $|1\rangle$ both correspond to the eigenvalue $+1$. Thus, this eigenvalue ($+1$) is degenerate. We say that the eigenspace corresponding to $\lambda =+1$ is 2-dimensional since it is spanned by two eigenvectors.